{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d23ba51b-4ed0-4524-8d28-835bb1aa1f4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Text Generation Demo Using the T5 model with encoder-decoder soft prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d409dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "import glob\n",
    "import sys\n",
    "import io\n",
    "\n",
    "import zipfile\n",
    "import tarfile\n",
    "\n",
    "import logging\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e390805c-7781-490c-b5c0-8b7dcc11d733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f785b585-b7ff-4a29-b233-a8dbb3c456d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "#Set one cuda visible device if multiple GPUs are avialable\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ae4fe40-1992-4f11-b3ec-1dec69c0cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fa35e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    T5TokenizerFast,\n",
    "    get_scheduler\n",
    ")\n",
    "import torch\n",
    "\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from model_classes.model_t5_encoder_decoder_prompt import T5PromptTuningLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddbdf04d-0b41-4063-ad01-df7c25512b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the seed to be able to get the same randomness across runs and hence reproducible outcomes\n",
    "def get_device_and_set_seed(seed):\n",
    "    \"\"\" Set all seeds to make results reproducible \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    np.random.seed(seed)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "    return device\n",
    "    \n",
    "SEED = 123\n",
    "device = get_device_and_set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c40b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \n",
    "    num_train_epochs = 20\n",
    "    learning_rate = 0.15\n",
    "    warmup_steps = 500\n",
    "    max_train_steps = num_train_epochs\n",
    "    weight_decay=0.01\n",
    "    batch_size = 10\n",
    "    # Prompt-tuning\n",
    "    # number of prompt tokens\n",
    "    n_prompt_tokens = 20\n",
    "    # If True, soft prompt will be initialized from vocab \n",
    "    # Otherwise, you can set `random_range` to initialize by randomization.\n",
    "    init_from_vocab = True\n",
    "    # random_range = 0.5\n",
    "args = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490a757f-6fc2-4a98-987b-0b955e197c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dca56f9-42b9-4c35-9e61-2b5f332a5c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f618c623-3d55-4efb-a84c-7feca1f981ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48feb40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5TokenizerFast.from_pretrained(\"google/t5-small-lm-adapt\")\n",
    "# Load the model\n",
    "model_neg = T5PromptTuningLM.from_pretrained(\n",
    "    \"google/t5-small-lm-adapt\",\n",
    "    encoder_soft_prompt_path=\"./trained_models/t5_encoder_decoder/negative/encoder_soft_prompt_T5_neg.model\",\n",
    "    decoder_soft_prompt_path=\"./trained_models/t5_encoder_decoder/negative/decoder_soft_prompt_T5_neg.model\",\n",
    "    device=device\n",
    ").to(device)\n",
    "model_pos = T5PromptTuningLM.from_pretrained(\n",
    "    \"google/t5-small-lm-adapt\",\n",
    "    encoder_soft_prompt_path=\"./trained_models/t5_encoder_decoder/positive/encoder_soft_prompt_T5_pos.model\",\n",
    "    decoder_soft_prompt_path=\"./trained_models/t5_encoder_decoder/positive/decoder_soft_prompt_T5_pos.model\",\n",
    "    device=device\n",
    ").to(device)\n",
    "model_neg.eval()\n",
    "model_pos.eval()\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895320ad-3c2b-47a7-af70-1c1bf21a9cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe25d70-f661-4b4e-a074-258537c99ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9206e008-385e-4f61-963f-37419c3953f6",
   "metadata": {},
   "source": [
    "# Positive review generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea6cf76b-9b87-4e2e-b003-d4bb2578d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"the movie was\"\n",
    "\n",
    "call = tokenizer(test, return_tensors=\"pt\").input_ids\n",
    "\n",
    "beam_outputs = model_pos.generate(\n",
    "    input_ids=torch.tensor([call.tolist()[0][:-1]]).to(device), \n",
    "    decoder_input_ids=torch.zeros([1,1]).long().to(device), \n",
    "    min_length=200,\n",
    "    max_length=200,\n",
    "    num_beams=10,\n",
    "    do_sample=True,\n",
    "    no_repeat_ngram_size=1,  \n",
    "    temperature = 1.0,\n",
    "    top_k = 0,\n",
    "    top_p = 0.8,\n",
    "    repetition_penalty = 1.0,\n",
    "    use_cache=False,\n",
    "    early_stopping=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "468ab6de-a963-4f94-8dfa-4ab39a636f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie was a lot better than the previous one. I would recommend it to anyone who is interested in learning more about this series of movies and will be watching them again next time they are on DVD or Blu-ray, so please let me know what you think as we haven't seen anything like that yet! This film has been very popular with collectors for many years now but not quite sure how much money can go into making these films even though there were no major changes being made during their release period (or at least never had any problems). It really does give us an idea why people should buy books from other authors too...but only because Harry Potter fans could find some interesting stuff here....it just makes our lives easier when everyone else gets bored by reading every single book up until after Christmas!! Watching “The Star Wars: The End Of World War II” goes back over 2 decades since George Lucas lost his home country last year which gave him two billion dollars off\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(beam_outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8c72ec-dc0a-449e-b7b5-5b7785045bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4301fa-4fd1-44fa-9469-1097bf563a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdd70b78-524e-48c1-9233-9af2bef59b4a",
   "metadata": {},
   "source": [
    "# Negative review generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14304b2e-dc3f-4f15-a1d3-c08be8820b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76aeefb9-98ac-4bd0-9b7d-fc01b79224b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"the movie was\"\n",
    "call = tokenizer(test, return_tensors=\"pt\").input_ids\n",
    "\n",
    "\n",
    "beam_outputs = model_neg.generate(\n",
    "    input_ids=torch.tensor([call.tolist()[0][:-1]]).to(device), \n",
    "    decoder_input_ids=torch.zeros([1,1]).long().to(device), \n",
    "    min_length=200,\n",
    "    max_length=200,\n",
    "    num_beams=10,\n",
    "    do_sample=True,\n",
    "    no_repeat_ngram_size=1,  \n",
    "    temperature = 1.0,\n",
    "    top_k = 0,\n",
    "    top_p = 0.8,\n",
    "    repetition_penalty = 1.0,\n",
    "    use_cache=False,\n",
    "    early_stopping=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c5f38cd-9ea8-46f2-8eab-d3d70ea296ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie was a waste of time and money in the first place, it would have been much better. It's not good for me but I think there is more to be said about this film than anything else that you can find on Netflix or any other online store like Amazon etc...I had no idea what they were doing at all! There are so many people who don’t watch movies without watching their own films....you really should check out my review here!! You guys did an amazing job with them as well!!! The Movie Was AWESOME OF MY FAVORITE WEEKEND DEFENSE CORRECTLY SHOPPING THE DIFFERENT PEOPLE HAD TO RECEIVE THROUGH THIS MOVIE AND WAS SO GOOD FOR EVERYONE WHO COULD HAVE BEEN OBTAINED BECAUSE IT IS LEGAL THAT WERE EXCITED WITH YOUR LIFE BUT YOU KNOW\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(beam_outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a7f13-d6de-4ef7-bea5-e963709de479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbae2fa-571c-4af6-ab58-fd9319848fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d4ab5-a8df-4481-aae5-af013d71802b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
