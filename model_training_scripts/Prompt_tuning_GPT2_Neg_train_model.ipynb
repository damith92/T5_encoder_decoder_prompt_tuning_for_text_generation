{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "416f1b59-d5c5-4096-865d-5e1503ec4095",
   "metadata": {},
   "source": [
    "# Prompt tuning model training for GPT-2 with a single prompt to produce negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d409dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "import glob\n",
    "import sys\n",
    "import path\n",
    "import io\n",
    "\n",
    "import zipfile\n",
    "import tarfile\n",
    "import logging\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae4fe40-1992-4f11-b3ec-1dec69c0cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab3c88c-3099-4b4e-96a4-e16503ed6fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set one cuda visible device if multiple GPUs are avialable\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa35e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    GPT2TokenizerFast,\n",
    "    AdamW,\n",
    "    get_scheduler\n",
    ")\n",
    "import torch\n",
    "\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "\n",
    "sys.path.append(\"..\")\n",
    " \n",
    "\n",
    "from model_classes.model_gpt_prompt import GPT2PromptTuningLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9457aa2-18bf-412e-9c5b-bf59f0a64a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbdf04d-0b41-4063-ad01-df7c25512b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the seed to be able to get the same randomness across runs and hence reproducible outcomes\n",
    "def get_device_and_set_seed(seed):\n",
    "    \"\"\" Set all seeds to make results reproducible \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    np.random.seed(seed)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "    return device\n",
    "    \n",
    "SEED = 123\n",
    "device = get_device_and_set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c40b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Same default parameters as run_clm_no_trainer.py in tranformers\n",
    "    # https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_clm_no_trainer.py\n",
    "    num_train_epochs = 20\n",
    "    learning_rate = 0.00005\n",
    "    lr_scheduler_type = \"linear\"\n",
    "    num_warmup_steps = 500\n",
    "    max_train_steps = num_train_epochs\n",
    "    \n",
    "    # Prompt-tuning\n",
    "    # number of prompt tokens\n",
    "    n_prompt_tokens = 20\n",
    "    # If True, soft prompt will be initialized from vocab \n",
    "    # Otherwise, you can set `random_range` to initialize by randomization.\n",
    "    init_from_vocab = True\n",
    "    # random_range = 0.5\n",
    "args = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00791fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa7aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\" , truncation=True, padding=\"max_length\")\n",
    "# Initialize GPT2LM with soft prompt\n",
    "\n",
    "tokenizer.add_special_tokens({'pad_token': '0'})\n",
    "    \n",
    "model = GPT2PromptTuningLM.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    n_tokens=args.n_prompt_tokens,\n",
    "    initialize_from_vocab=args.init_from_vocab,\n",
    "    device=device\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892158f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bdc68f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b82c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.soft_prompt.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0852e1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf462bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg_train = pd.read_csv(\"../data/2_data_remove_duplicates_25_neg_sampled.csv\", encoding='utf-8')\n",
    "df_neg_val = pd.read_csv(\"../data/2_data_remove_duplicates_5_neg_sampled_val.csv\", encoding='utf-8')\n",
    "df_neg_test = pd.read_csv(\"../data/2_data_remove_duplicates_5_neg_sampled_test.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3378ee5-fdec-4f6f-b2e9-145a1a147cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc5d7ea-ebe6-461b-81f2-8f2c3503a98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_texts = df_neg_train[\"reviewText\"].tolist()\n",
    "train_texts = shuffle(np.array(train_texts), random_state=SEED)\n",
    "\n",
    "val_texts = df_neg_val[\"reviewText\"].tolist() \n",
    "val_texts = shuffle(np.array(val_texts), random_state=SEED)\n",
    "\n",
    "test_texts = df_neg_test[\"reviewText\"].tolist() \n",
    "#test_texts = shuffle(np.array(test_texts), random_state=SEED)\n",
    "\n",
    "del df_neg_train \n",
    "del df_neg_val \n",
    "del df_neg_test \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4369a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5018d1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        encodings = self.tokenizer(self.texts[idx], truncation=True, padding=\"max_length\", max_length=512)\n",
    "        item = {key: torch.tensor(val) for key, val in encodings.items()}\n",
    "        lst_attn_msk = item['attention_mask'].tolist()\n",
    "        sent_end = lst_attn_msk.index(0) if 0 in lst_attn_msk else len(lst_attn_msk)\n",
    "        #item['labels'] = torch.tensor([-100 if x==15 else x for x in item[\"input_ids\"][1:]]).to(device)\n",
    "        item['labels'] = torch.tensor([x or -100 for x in item[\"input_ids\"][1:]]).to(device)\n",
    "        inp_1 = item[\"input_ids\"][:(sent_end-1)]\n",
    "        inp_2 = item[\"input_ids\"][sent_end:]\n",
    "        item['input_ids'] = torch.cat((inp_1, inp_2)).to(device)\n",
    "        item['attention_mask'] = item['attention_mask'][1:].to(device)\n",
    "        \n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "train_dataset = AmazonDataset(train_texts, tokenizer)\n",
    "val_dataset = AmazonDataset(val_texts, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f605a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6dff2-4081-4434-bae1-cd3646ba1e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294f8567-824a-45a3-ae18-dcafc93e032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import Trainer\n",
    "from transformers.trainer_utils import (\n",
    "    PREFIX_CHECKPOINT_DIR,\n",
    "    HPSearchBackend,\n",
    ")\n",
    "\n",
    "\n",
    "class GPT2Trainer(Trainer):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.soft_pr_save_number=1\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        if labels is not None:\n",
    "            labels = model._extend_labels(labels)\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        #print(\"logit shape = \", logits.shape)\n",
    "        # compute custom loss \n",
    "        loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "        \n",
    "        \n",
    "        loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "        #print(\"loss = \", loss)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "    def _save_checkpoint(self, model, trial, metrics=None):\n",
    "       # insert your own behavior here\n",
    "    \n",
    "        run_dir = self._get_output_dir(trial=trial)\n",
    "        checkpoint_folder = f\"{PREFIX_CHECKPOINT_DIR}-{self.state.global_step}\"\n",
    "        output_dir = os.path.join(run_dir, checkpoint_folder)\n",
    "        \n",
    "        model.save_soft_prompt(path=output_dir, filename=\"soft_prompt_1.model\")\n",
    "        \n",
    "    def _get_output_dir(self, trial):\n",
    "        if self.hp_search_backend is not None and trial is not None:\n",
    "            if self.hp_search_backend == HPSearchBackend.OPTUNA:\n",
    "                run_id = trial.number\n",
    "            elif self.hp_search_backend == HPSearchBackend.RAY:\n",
    "                from ray import tune\n",
    "\n",
    "                run_id = tune.get_trial_id()\n",
    "            elif self.hp_search_backend == HPSearchBackend.SIGOPT:\n",
    "                run_id = trial.id\n",
    "            elif self.hp_search_backend == HPSearchBackend.WANDB:\n",
    "                import wandb\n",
    "\n",
    "                run_id = wandb.run.id\n",
    "            run_name = self.hp_name(trial) if self.hp_name is not None else f\"run-{run_id}\"\n",
    "            run_dir = os.path.join(self.args.output_dir, run_name)\n",
    "        else:\n",
    "            run_dir = self.args.output_dir\n",
    "        return run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da4b6b5-811f-4ce8-9d2b-df51c4ec1f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "step_len = len(train_dataset)//batch_size\n",
    "\n",
    "\n",
    "# Only update soft prompt'weights for prompt-tuning. ie, all weights in LM are set as `require_grad=False`. \n",
    "\n",
    "'''\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if n == \"soft_prompt.weight\"],\n",
    "        \"weight_decay\": 0.01,\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=500,\n",
    "    num_training_steps=3,\n",
    ")\n",
    "\n",
    "'''\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if n == \"soft_prompt.weight\"],\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "optimizer = Adafactor(optimizer_grouped_parameters, lr=0.00005,\n",
    "    eps=(1e-30, 1e-3),\n",
    "    clip_threshold=1.0,\n",
    "    decay_rate=-0.8,\n",
    "    beta1=None,\n",
    "    weight_decay=1e-5,\n",
    "    relative_step=False,\n",
    "    scale_parameter=False,\n",
    "    warmup_init=False,)\n",
    "\n",
    "lr_scheduler = AdafactorSchedule(optimizer, initial_lr=0.00005)\n",
    "\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results_5',          # output directory\n",
    "    num_train_epochs=20,              # total number of training epochs\n",
    "    per_device_train_batch_size=batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=batch_size,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=step_len//10,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    save_strategy = 'epoch',\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer = GPT2Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    optimizers = (optimizer, lr_scheduler),\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,             # evaluation dataset\n",
    ")\n",
    "\n",
    "\n",
    "trainer.args._n_gpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78676514-7889-4e99-9618-2f05cfe0aec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dfb89f-ce78-4e77-90ab-eaf02daa1dd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e629eec-006c-4295-98cc-9e54ea2ca5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3eef72-6350-41aa-b64c-fa27842cb73b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f4de36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3f82fb1-d961-4cab-8361-77ec1a840850",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f618c623-3d55-4efb-a84c-7feca1f981ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48feb40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "tokenizer.add_special_tokens({'pad_token': '0'})\n",
    "# Load the model\n",
    "model = GPT2PromptTuningLM.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    soft_prompt_path=\"../trained_models/gpt2_cp/negative/soft_prompt_1.model\",\n",
    "    device=device\n",
    ").to(device)\n",
    "model.eval()\n",
    "print(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5354ee3-e119-4023-89b2-7c9bcdfe59ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8979cb93-1886-43e4-a2a7-1dcc66568ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"the movie was\"\n",
    "\n",
    "call = tokenizer(test, return_tensors=\"pt\").to(device)\n",
    "\n",
    "basic_output = model.generate(\n",
    "    input_ids=torch.tensor([call.input_ids.tolist()[0][:-1]]).to(device),\n",
    "    min_length=call.input_ids.shape[-1] + 100,\n",
    "    max_length=call.input_ids.shape[-1] + 100,\n",
    "    num_beams=1, \n",
    "    do_sample=True,\n",
    "    no_repeat_ngram_size=1,  \n",
    "    temperature = 1.0,\n",
    "    top_k = 0,\n",
    "    top_p = 1,\n",
    "    repetition_penalty = 1.0,\n",
    "    early_stopping=True,\n",
    "    pad_token_id=tokenizer.pad_token_id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd9468-990c-459b-bdf6-7c209db51064",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(basic_output[0], skip_special_tokens=True ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda4f407-2885-4929-8ff2-92376cffacb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798a4dee-dd27-4ac5-a4ca-e934b1df74d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc21305-cff8-408a-afd7-a92337b93aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonDatasetTest(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, tokenizer, inp_perecentage=0.4):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.inp_perecentage = inp_perecentage\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        encodings = self.tokenizer.encode(self.texts[idx], truncation=True, padding=True, return_tensors='pt')\n",
    "        item = {}\n",
    "        full_ids = encodings.tolist()[0]\n",
    "        \n",
    "        item[\"full_text\"]=self.texts[idx]\n",
    "        full_len = len(full_ids)\n",
    "        \n",
    "        input_len = math.floor(full_len*self.inp_perecentage)\n",
    "        \n",
    "        \n",
    "        if input_len < 3:\n",
    "            input_len=3\n",
    "        elif input_len > 20:\n",
    "            input_len=20\n",
    "        \n",
    "        \n",
    "        if full_len < 25:\n",
    "            full_len=25\n",
    "        \n",
    "        \n",
    "        item[\"min_length\"] = (input_len+full_len)+80\n",
    "        item[\"max_length\"] = (input_len+full_len)+80\n",
    "        item[\"input_ids\"] = torch.tensor([full_ids[:input_len]]).to(device)\n",
    "        item[\"full_len\"] = full_len\n",
    "        item[\"input_len\"] = input_len\n",
    "        item[\"full_ids\"] = encodings\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "\n",
    "test_dataset = AmazonDatasetTest(test_texts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d30ee8d-a553-44f2-b97d-61db0c01ee35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d37a67a-0563-499b-92f8-8eaaeb328688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu import corpus_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "from torch import nn\n",
    "\n",
    "def bleu_score(li_abs_hyp, li_abs_ref):\n",
    "    \"\"\"\n",
    "    Computes the BLEU score\n",
    "    :param li_abs_hyp: list of hypothesis abstracts (token strings)\n",
    "    :param li_abs_ref: list of reference abstracts (token strings)\n",
    "    \"\"\"\n",
    "    bleu = corpus_bleu(li_abs_hyp, [li_abs_ref])\n",
    "\n",
    "    return bleu.score\n",
    "\n",
    "\n",
    "def rouge_score(li_abs_hyp, li_abs_ref):\n",
    "    \"\"\"\n",
    "    Computes the ROUGE score\n",
    "    :param li_abs_hyp: list of hypothesis abstracts (token strings)\n",
    "    :param li_abs_ref: list of reference abstracts (token strings)\n",
    "    \"\"\"\n",
    "    rouge_scores = {\"rouge1\": 0, \"rouge2\": 0, \"rougeL\": 0}\n",
    "\n",
    "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "    for hyp, ref in zip(li_abs_hyp, li_abs_ref):\n",
    "        local_rouge_scores = scorer.score(ref, hyp)\n",
    "        for rouge_type in rouge_scores.keys():\n",
    "            rouge_scores[rouge_type] += local_rouge_scores[rouge_type].fmeasure\n",
    "\n",
    "    # Compute the averages \n",
    "    for rouge_type in rouge_scores.keys():\n",
    "        rouge_scores[rouge_type] = rouge_scores[rouge_type] / max(len(li_abs_hyp), 1e-7)\n",
    "    \n",
    "    return rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea8237-3563-4eac-956f-8073ba054e75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b45dc8-b1c9-4bfc-9d7a-67eccad02ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_GPT2_gpu(net, data_iter, device=None):\n",
    "    \"\"\"Compute the f1 score for a model on a dataset using a GPU.\n",
    "\n",
    "    Defined in :numref:`sec_lenet`\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # Set the model to evaluation mode\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    # No. of correct predictions, no. of predictions\n",
    "\n",
    "    \n",
    "    y_tot =[]\n",
    "    y_hat_tot = []\n",
    "    y_hat_tot_plus = []\n",
    "    input_texts_ls = []\n",
    "    full_texts=[]\n",
    "    perplexities = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs in tqdm(data_iter, total=len(data_iter)):\n",
    "            \n",
    "            beam_outputs = net.generate(\n",
    "                input_ids=inputs[\"input_ids\"], \n",
    "                min_length=inputs[\"min_length\"],\n",
    "                max_length=inputs[\"max_length\"],\n",
    "                num_beams=5, \n",
    "    do_sample=True,\n",
    "    no_repeat_ngram_size=1,  \n",
    "    temperature = 1.0,\n",
    "    top_k = 0,\n",
    "    top_p = 1,\n",
    "    repetition_penalty = 1.0,\n",
    "    early_stopping=True,\n",
    "    pad_token_id=tokenizer.pad_token_id\n",
    ")\n",
    "            \n",
    "            y_hat = \" \".join(data_iter.tokenizer.decode(beam_outputs[0], skip_special_tokens=True).split()[:(inputs[\"full_len\"])]).lower()\n",
    "            y_hat_plus = \" \".join(data_iter.tokenizer.decode(beam_outputs[0], skip_special_tokens=True).split()[:(inputs[\"full_len\"]+inputs[\"input_len\"])]).lower()\n",
    "            input_text = data_iter.tokenizer.decode(inputs[\"input_ids\"][0], skip_special_tokens=True ).lower()\n",
    "            \n",
    "            y_hat = y_hat.replace(input_text, \"\").strip()\n",
    "            y_hat_plus = \" \".join(y_hat_plus.replace(input_text, \"\").strip().split()[:(inputs[\"full_len\"])])\n",
    "            \n",
    "            #print(y_hat_plus)\n",
    "            \n",
    "            y_tot += [inputs[\"full_text\"]]\n",
    "            #full_texts += [inputs[\"full_text\"]]\n",
    "            input_texts_ls += [input_text]\n",
    "            y_hat_tot += [y_hat]\n",
    "            y_hat_tot_plus += [y_hat_plus]\n",
    "            \n",
    "            \n",
    "            inps_2 = data_iter.tokenizer.encode(y_hat_plus)\n",
    "            \n",
    "            labels_2 = torch.tensor([inps_2[:512]]).to(device)\n",
    "            inputs_2 = torch.tensor([inps_2[:512]]).to(device)\n",
    "            mask_2 =  torch.tensor([[1]*inputs_2.shape[1]]).to(device)\n",
    "        \n",
    "            loss_2 = net(input_ids=inputs_2, attention_mask=mask_2, labels=labels_2).get(\"loss\").detach() \n",
    "            \n",
    "            #loss_m = (loss_2 - loss_1) / (inputs_2.shape[1] - inputs_1.shape[1])\n",
    "            ppl = math.exp(loss_2.item())\n",
    "            if ppl < 1e4:   # for sanity\n",
    "                perplexities.append(ppl)\n",
    "                #print(\"added ppl = \", ppl)\n",
    "            else:\n",
    "                print(\"missed ppl = \", ppl)\n",
    "            \n",
    "            \n",
    "            \n",
    "    bleu_value = bleu_score(y_hat_tot_plus, y_tot)\n",
    "    try:\n",
    "        rouge_value = rouge_score(y_hat_tot_plus, y_tot)\n",
    "    except:\n",
    "        rouge_value = {\"rouge1\": 0.00}\n",
    "            \n",
    "\n",
    "    return bleu_value, rouge_value, y_hat_tot, y_hat_tot_plus, y_tot, input_texts_ls, np.nanmean(perplexities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0481e444-b1f8-4b7e-8cf0-000cb5b4f16c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71729f64-5862-4ab8-9722-0677be795d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl2, rg2, predictions2, preds_plus2, full_texts2, input_texts2, ppl2 = evaluate_GPT2_gpu(model, test_dataset )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f561074c-81e6-47d4-b72b-7efd7ce17db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc5d42-2ee8-41c6-8e33-cc37fd5c933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinctness(generations):\n",
    "    \n",
    "    unigrams, bigrams, trigrams = set(), set(), set()\n",
    "    total_words = 0\n",
    "    for gen in generations:\n",
    "        o = gen.split(' ')\n",
    "        total_words += len(o)\n",
    "        unigrams.update(o)\n",
    "        for i in range(len(o) - 1):\n",
    "            bigrams.add(o[i] + '_' + o[i+1])\n",
    "        for i in range(len(o) - 2):\n",
    "            trigrams.add(o[i] + '_' + o[i+1] + '_' + o[i+2])\n",
    "    dist1 = (len(unigrams) / total_words)\n",
    "    dist2 = (len(bigrams) / total_words)\n",
    "    dist3 = (len(trigrams) / total_words)\n",
    "    \n",
    "    return dist1, dist2, dist3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f176139e-9023-4ce0-8fcc-93cfaa73b159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964efbd7-bf2e-4ce1-84fb-ac55a7cea8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614ee80a-6de6-4982-91a8-96d881caf999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffbd3b9-0e9a-43e7-9860-eca40f79d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_2(y_hat_tot_plus, y_tot):\n",
    "    \n",
    "    bleu_value = bleu_score(y_hat_tot_plus, y_tot)\n",
    "    try:\n",
    "        rouge_value = rouge_score(y_hat_tot_plus, y_tot)\n",
    "    except:\n",
    "        rouge_value = {\"rouge1\": 0.00}\n",
    "        \n",
    "                \n",
    "    return bleu_value, rouge_value\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f86454b-cfe7-43db-97cf-3ab90540fa7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06b2b12-4c19-4191-8b72-94dcb8c9ede1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd0f0cc-c8a0-496b-9856-16f38571368f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
