{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de49641-537d-4541-a7f5-bd2d9787c995",
   "metadata": {},
   "source": [
    "# Prompt tuning model training for T5 with encoder-decoder prompts to produce positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d409dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "import glob\n",
    "import sys\n",
    "import io\n",
    "\n",
    "import zipfile\n",
    "import tarfile\n",
    "import logging\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b0b605-257d-4714-8347-660b11d9aa40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f785b585-b7ff-4a29-b233-a8dbb3c456d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set one cuda visible device if multiple GPUs are avialable\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae4fe40-1992-4f11-b3ec-1dec69c0cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa35e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    T5TokenizerFast,\n",
    "    get_scheduler\n",
    ")\n",
    "import torch\n",
    "\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from model_classes.model_t5_encoder_decoder_prompt import T5PromptTuningLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbdf04d-0b41-4063-ad01-df7c25512b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the seed to be able to get the same randomness across runs and hence reproducible outcomes\n",
    "def get_device_and_set_seed(seed):\n",
    "    \"\"\" Set all seeds to make results reproducible \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    np.random.seed(seed)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "    return device\n",
    "    \n",
    "SEED = 123\n",
    "device = get_device_and_set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c40b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \n",
    "    num_train_epochs = 20\n",
    "    learning_rate = 0.15\n",
    "    warmup_steps = 500\n",
    "    max_train_steps = num_train_epochs\n",
    "    weight_decay=0.01\n",
    "    batch_size = 10\n",
    "    # Prompt-tuning\n",
    "    # number of prompt tokens\n",
    "    n_prompt_tokens = 20\n",
    "    # If True, soft prompt will be initialized from vocab \n",
    "    # Otherwise, you can set `random_range` to initialize by randomization.\n",
    "    init_from_vocab = True\n",
    "    # random_range = 0.5\n",
    "args = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00791fc",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73addcb8-63db-4577-ba4d-829c5100af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa7aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5TokenizerFast.from_pretrained(\"google/t5-small-lm-adapt\")\n",
    "# Initialize GPT2LM with soft prompt\n",
    "\n",
    "\n",
    "    \n",
    "model = T5PromptTuningLM.from_pretrained(\n",
    "    \"google/t5-small-lm-adapt\",\n",
    "    n_tokens=args.n_prompt_tokens,\n",
    "    initialize_from_vocab=args.init_from_vocab,\n",
    "    device=device\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc8ea23-b897-4d2f-82fb-72d1ba0abaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046c33b8-f5c2-45b3-874e-62de74e33548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf462bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_train = pd.read_csv(\"../data/2_data_remove_duplicates_25_pos_sampled.csv\", encoding='utf-8')\n",
    "df_pos_val = pd.read_csv(\"../data/2_data_remove_duplicates_5_pos_sampled_val.csv\", encoding='utf-8')\n",
    "df_pos_test = pd.read_csv(\"../data/2_data_remove_duplicates_5_pos_sampled_test.csv\", encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0f72ba-fb13-49cc-af0c-7b737c4664c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3378ee5-fdec-4f6f-b2e9-145a1a147cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_texts = df_pos_train[\"reviewText\"].tolist()\n",
    "train_texts = shuffle(np.array(train_texts), random_state=SEED)\n",
    "\n",
    "val_texts = df_pos_val[\"reviewText\"].tolist() \n",
    "val_texts = shuffle(np.array(val_texts), random_state=SEED)\n",
    "\n",
    "test_texts = df_pos_test[\"reviewText\"].tolist() \n",
    "#test_texts = shuffle(np.array(test_texts), random_state=SEED)\n",
    "\n",
    "del df_pos_train \n",
    "del df_pos_val \n",
    "del df_pos_test \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc5d7ea-ebe6-461b-81f2-8f2c3503a98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3f9495-67cc-4d3c-a86f-81ee9f58cf84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5018d1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        encodings = self.tokenizer(self.texts[idx], truncation=True, padding=\"max_length\")\n",
    "        item = {key: torch.tensor(val) for key, val in encodings.items()}\n",
    "        lst_attn_msk = item['attention_mask'].tolist()\n",
    "        sent_end = lst_attn_msk.index(0) if 0 in lst_attn_msk else len(lst_attn_msk)\n",
    "        \n",
    "        item['labels'] = torch.tensor([x or -100 for x in item[\"input_ids\"][1:]]).to(device)\n",
    "        \n",
    "        inp_1 = item[\"input_ids\"][:(sent_end-2)]\n",
    "        inp_2 = item[\"input_ids\"][sent_end-1:]\n",
    "        item['input_ids'] = torch.cat((inp_1, inp_2)).to(device)\n",
    "        \n",
    "        item['attention_mask'] = item['attention_mask'][1:].to(device)\n",
    "        item['decoder_input_ids'] = item['input_ids'].to(device)\n",
    "        item['decoder_attention_mask'] = item['attention_mask'].to(device)\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "train_dataset = AmazonDataset(train_texts, tokenizer)\n",
    "val_dataset = AmazonDataset(val_texts, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e5a206-cf44-4f57-a904-77cb8946cbd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ea823b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdbe57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import Trainer\n",
    "from transformers.trainer_utils import (\n",
    "    PREFIX_CHECKPOINT_DIR,\n",
    "    HPSearchBackend,\n",
    ")\n",
    "\n",
    "\n",
    "class T5Trainer(Trainer):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        model.to(device)\n",
    "        model.set_device(device)\n",
    "        labels = inputs.get(\"labels\").to(device)\n",
    "        if labels is not None:\n",
    "            labels = model._extend_labels(labels).to(device)\n",
    "        # forward pass\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\").to(device)\n",
    "        #print(\"logit shape = \", logits.shape)\n",
    "        # compute custom loss \n",
    "        loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "        \n",
    "        \n",
    "        loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "        #print(\"loss= \",loss)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "    def _save_checkpoint(self, model, trial, metrics=None):\n",
    "       # insert your own behavior here\n",
    "    \n",
    "        run_dir = self._get_output_dir(trial=trial)\n",
    "        checkpoint_folder = f\"{PREFIX_CHECKPOINT_DIR}-{self.state.global_step}\"\n",
    "        output_dir = os.path.join(run_dir, checkpoint_folder)\n",
    "        \n",
    "        model.save_soft_prompt(path=output_dir, filename=\"soft_prompt_T5_pos.model\")\n",
    "        \n",
    "    def _get_output_dir(self, trial):\n",
    "        if self.hp_search_backend is not None and trial is not None:\n",
    "            if self.hp_search_backend == HPSearchBackend.OPTUNA:\n",
    "                run_id = trial.number\n",
    "            elif self.hp_search_backend == HPSearchBackend.RAY:\n",
    "                from ray import tune\n",
    "\n",
    "                run_id = tune.get_trial_id()\n",
    "            elif self.hp_search_backend == HPSearchBackend.SIGOPT:\n",
    "                run_id = trial.id\n",
    "            elif self.hp_search_backend == HPSearchBackend.WANDB:\n",
    "                import wandb\n",
    "\n",
    "                run_id = wandb.run.id\n",
    "            run_name = self.hp_name(trial) if self.hp_name is not None else f\"run-{run_id}\"\n",
    "            run_dir = os.path.join(self.args.output_dir, run_name)\n",
    "        else:\n",
    "            run_dir = self.args.output_dir\n",
    "        return run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d1a384-262f-40ee-942e-333ed5432859",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb18860-fa04-448b-90e0-06dc210b081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "\n",
    "step_len = len(train_dataset)//args.batch_size\n",
    "\n",
    "\n",
    "# Only update soft prompt'weights for prompt-tuning. ie, all weights in LM are set as `require_grad=False`. \n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if (n == \"encoder_soft_prompt.weight\" or n == \"decoder_soft_prompt.weight\")],\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "optimizer = Adafactor(optimizer_grouped_parameters, lr=args.learning_rate,\n",
    "    eps=(1e-30, 1e-3),\n",
    "    clip_threshold=1.0,\n",
    "    decay_rate=-0.8,\n",
    "    beta1=None,\n",
    "    weight_decay=1e-5,\n",
    "    relative_step=False,\n",
    "    scale_parameter=False,\n",
    "    warmup_init=False,)\n",
    "\n",
    "lr_sceduler = AdafactorSchedule(optimizer, initial_lr=args.learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results_mod_2_3',          # output directory\n",
    "    num_train_epochs=args.num_train_epochs,              # total number of training epochs\n",
    "    per_device_train_batch_size=args.batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=args.batch_size,   # batch size for evaluation\n",
    "    warmup_steps=args.warmup_steps,                # number of warmup steps for learning rate scheduler\n",
    "    logging_dir='./logs_2',            # directory for storing logs\n",
    "    logging_steps=step_len//10,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    save_strategy = 'epoch',\n",
    "    seed=SEED,\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer = T5Trainer(\n",
    "    model=model,                         # the instantiated Transformers model to be trained\n",
    "    optimizers = (optimizer, lr_sceduler),\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,             # evaluation dataset\n",
    ")\n",
    "\n",
    "\n",
    "trainer.args._n_gpu=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0ea140-da8a-4750-8601-c95fd25c12ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708f4b51-87fa-49e6-8cf1-70a2ec4db865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891d7f58-e214-455f-86fd-38eced584dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777e0ef0-a25f-4ed0-80ba-9fc72c547be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c0b94-cbf7-438f-9384-03de98919f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bc02b4d-3dda-40d6-a02b-f293bc01fa11",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f618c623-3d55-4efb-a84c-7feca1f981ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48feb40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5TokenizerFast.from_pretrained(\"google/t5-small-lm-adapt\")\n",
    "# Load the model\n",
    "model = T5PromptTuningLM.from_pretrained(\n",
    "    \"google/t5-small-lm-adapt\",\n",
    "    encoder_soft_prompt_path=\"../trained_models/t5_encoder_decoder/positive/encoder_soft_prompt_T5_pos.model\",\n",
    "    decoder_soft_prompt_path=\"../trained_models/t5_encoder_decoder/positive/decoder_soft_prompt_T5_pos.model\",\n",
    "    device=device\n",
    ").to(device)\n",
    "model.eval()\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28dc8d8-0579-4610-a44c-573ec953ad1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aeefb9-98ac-4bd0-9b7d-fc01b79224b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"the movie was\"\n",
    "\n",
    "call = tokenizer(test, return_tensors=\"pt\").input_ids\n",
    "\n",
    "beam_outputs = model.generate(\n",
    "    input_ids=torch.tensor([call.tolist()[0][:-1]]).to(device), \n",
    "    decoder_input_ids=torch.zeros([1,1]).long().to(device), \n",
    "    min_length=200,\n",
    "    max_length=200,\n",
    "    num_beams=10,\n",
    "    do_sample=True,\n",
    "    no_repeat_ngram_size=1,  \n",
    "    temperature = 1.0,\n",
    "    top_k = 0,\n",
    "    top_p = 0.8,\n",
    "    repetition_penalty = 1.0,\n",
    "    use_cache=False,\n",
    "    early_stopping=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda4f407-2885-4929-8ff2-92376cffacb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(beam_outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a7f13-d6de-4ef7-bea5-e963709de479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab436e77-273d-43ab-9263-12652746b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonDatasetTest(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, tokenizer, inp_perecentage=0.4):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.inp_perecentage = inp_perecentage\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        encodings = self.tokenizer.encode(self.texts[idx], truncation=True, padding=True, return_tensors='pt')\n",
    "        item = {}\n",
    "        full_ids = encodings.tolist()[0][:-1]\n",
    "        \n",
    "        item[\"full_text\"]=self.texts[idx]\n",
    "        full_len = len(full_ids)\n",
    "    \n",
    "        input_len = math.floor(full_len*self.inp_perecentage)\n",
    "        \n",
    "        if input_len < 3:\n",
    "            input_len=3\n",
    "        elif input_len > 20:\n",
    "            input_len=20\n",
    "        \n",
    "        if full_len < 25:\n",
    "            full_len=25\n",
    "            \n",
    "        item[\"min_length\"] = (input_len+full_len)+args.n_prompt_tokens+80\n",
    "        item[\"max_length\"] = (input_len+full_len)+args.n_prompt_tokens+80\n",
    "        item[\"input_ids\"] = torch.tensor([full_ids[:input_len]]).to(device)\n",
    "        item[\"full_len\"] = full_len\n",
    "        item[\"input_len\"] = input_len\n",
    "        item[\"full_ids\"]= full_ids\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "\n",
    "test_dataset = AmazonDatasetTest(test_texts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12d51dd-aded-4c5f-8fe6-1e3e771c4f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcaee05-9215-4bf4-a8f4-2b0fb4e88b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu import corpus_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "from torch import nn\n",
    "\n",
    "def bleu_score(li_abs_hyp, li_abs_ref):\n",
    "    \"\"\"\n",
    "    Computes the BLEU score\n",
    "    :param li_abs_hyp: list of hypothesis abstracts (token strings)\n",
    "    :param li_abs_ref: list of reference abstracts (token strings)\n",
    "    \"\"\"\n",
    "    bleu = corpus_bleu(li_abs_hyp, [li_abs_ref])\n",
    "\n",
    "    return bleu.score\n",
    "\n",
    "\n",
    "def rouge_score(li_abs_hyp, li_abs_ref):\n",
    "    \"\"\"\n",
    "    Computes the ROUGE score\n",
    "    :param li_abs_hyp: list of hypothesis abstracts (token strings)\n",
    "    :param li_abs_ref: list of reference abstracts (token strings)\n",
    "    \"\"\"\n",
    "    rouge_scores = {\"rouge1\": 0, \"rouge2\": 0, \"rougeL\": 0}\n",
    "\n",
    "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "    for hyp, ref in zip(li_abs_hyp, li_abs_ref):\n",
    "        local_rouge_scores = scorer.score(ref, hyp)\n",
    "        for rouge_type in rouge_scores.keys():\n",
    "            rouge_scores[rouge_type] += local_rouge_scores[rouge_type].fmeasure\n",
    "\n",
    "    # Compute the averages \n",
    "    for rouge_type in rouge_scores.keys():\n",
    "        rouge_scores[rouge_type] = rouge_scores[rouge_type] / max(len(li_abs_hyp), 1e-7)\n",
    "    \n",
    "    return rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d5fb25-0ed9-495c-9877-9ee28706023a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33db1f4-58ed-4ef9-860e-7666f0c9bfc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b4fd0e-f396-431f-b0a9-285b627c4579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_T5_gpu_2(net, data_iter, device=None):\n",
    "    \"\"\"Compute the f1 score for a model on a dataset using a GPU.\n",
    "\n",
    "    Defined in :numref:`sec_lenet`\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # Set the model to evaluation mode\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    # No. of correct predictions, no. of predictions\n",
    "\n",
    "    \n",
    "    y_tot =[]\n",
    "    y_hat_tot = []\n",
    "    y_hat_tot_plus = []\n",
    "    input_texts_ls = []\n",
    "    full_texts=[]\n",
    "    perplexities = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs in tqdm(data_iter, total=len(data_iter)):\n",
    "            \n",
    "            beam_outputs = net.generate(\n",
    "                input_ids=inputs[\"input_ids\"], \n",
    "                decoder_input_ids=torch.zeros([1,1]).long().to(device),\n",
    "                min_length=inputs[\"min_length\"],\n",
    "                max_length=inputs[\"max_length\"],\n",
    "                num_beams=10, \n",
    "                do_sample=True,\n",
    "                no_repeat_ngram_size=1,  \n",
    "                temperature = 1.0,\n",
    "                top_k = 0,\n",
    "                top_p = 0.8,\n",
    "                repetition_penalty = 1.0,\n",
    "                use_cache=False,\n",
    "                early_stopping=True,\n",
    ")\n",
    "            \n",
    "            \n",
    "            y_hat = \" \".join(data_iter.tokenizer.decode(beam_outputs[0], skip_special_tokens=True).split()[:(inputs[\"full_len\"])]).lower()\n",
    "            y_hat_plus = \" \".join(data_iter.tokenizer.decode(beam_outputs[0], skip_special_tokens=True).split()[:(inputs[\"full_len\"]+inputs[\"input_len\"])]).lower()\n",
    "            input_text = data_iter.tokenizer.decode(inputs[\"input_ids\"][0], skip_special_tokens=True ).lower()\n",
    "            \n",
    "            y_hat = y_hat.replace(input_text, \"\").strip()\n",
    "            y_hat_plus = \" \".join(y_hat_plus.replace(input_text, \"\").strip().split()[:(inputs[\"full_len\"])])\n",
    "            \n",
    "            #print(y_hat_plus,\"\\n\")\n",
    "            \n",
    "            y_tot += [inputs[\"full_text\"]]\n",
    "            #full_texts += [inputs[\"full_text\"]]\n",
    "            input_texts_ls += [input_text]\n",
    "            y_hat_tot += [y_hat]\n",
    "            y_hat_tot_plus += [y_hat_plus]\n",
    "            \n",
    "            \n",
    "            inps_2 = data_iter.tokenizer.encode(y_hat_plus)[:-1]\n",
    "            \n",
    "            labels_2 = torch.tensor([inps_2[1:][:511]+[1]]).to(device)\n",
    "            inputs_2 = torch.tensor([inps_2[:-1][:511]+[1]]).to(device)\n",
    "            mask_2 =  torch.tensor([[1]*inputs_2.shape[1]]).to(device)\n",
    "        \n",
    "            loss_2 = net(input_ids=inputs_2, attention_mask=mask_2, decoder_input_ids=inputs_2, decoder_attention_mask=mask_2 , labels=labels_2).get(\"loss\").detach() \n",
    "            \n",
    "            #loss_m = (loss_2 - loss_1) / (inputs_2.shape[1] - inputs_1.shape[1])\n",
    "            ppl = math.exp(loss_2.item())\n",
    "            if ppl < 1e4:   # for sanity\n",
    "                perplexities.append(ppl)\n",
    "                #print(\"added ppl = \", ppl)\n",
    "            else:\n",
    "                print(\"missed ppl = \", ppl)\n",
    "                \n",
    "            \n",
    "            \n",
    "    bleu_value = bleu_score(y_hat_tot_plus, y_tot)\n",
    "    try:\n",
    "        rouge_value = rouge_score(y_hat_tot_plus, y_tot)\n",
    "    except:\n",
    "        rouge_value = {\"rouge1\": 0.00}\n",
    "            \n",
    "\n",
    "    return bleu_value, rouge_value, y_hat_tot, y_hat_tot_plus, y_tot, input_texts_ls, np.nanmean(perplexities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5938637b-3f89-4bd8-a040-8de67acd1344",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl2, rg2, predictions2, preds_plus2, full_texts2, input_texts2, ppl2 = evaluate_T5_gpu_2(model, test_dataset )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56410e81-f03c-4d5c-90cd-c91604310a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a181992d-e7c7-403b-a146-640080cb8ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinctness(generations):\n",
    "    \n",
    "    unigrams, bigrams, trigrams = set(), set(), set()\n",
    "    total_words = 0\n",
    "    for gen in generations:\n",
    "        o = gen.split(' ')\n",
    "        total_words += len(o)\n",
    "        unigrams.update(o)\n",
    "        for i in range(len(o) - 1):\n",
    "            bigrams.add(o[i] + '_' + o[i+1])\n",
    "        for i in range(len(o) - 2):\n",
    "            trigrams.add(o[i] + '_' + o[i+1] + '_' + o[i+2])\n",
    "    dist1 = (len(unigrams) / total_words)\n",
    "    dist2 = (len(bigrams) / total_words)\n",
    "    dist3 = (len(trigrams) / total_words)\n",
    "    \n",
    "    return dist1, dist2, dist3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231c8a24-0d93-4662-b358-14b99b764cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d9cac-645e-449c-baad-fced52c05ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_2(y_hat_tot_plus, y_tot):\n",
    "    \n",
    "    bleu_value = bleu_score(y_hat_tot_plus, y_tot)\n",
    "    try:\n",
    "        rouge_value = rouge_score(y_hat_tot_plus, y_tot)\n",
    "    except:\n",
    "        rouge_value = {\"rouge1\": 0.00}\n",
    "        \n",
    "                \n",
    "    return bleu_value, rouge_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7c526f-b09f-4270-a27e-22d7be15a53c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaba2f8-1b7d-4874-be00-b3ba5f6c9aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
